# Diagrama de Arquitetura AWS EKS + Datadog Stack

## VisÃ£o Geral da Arquitetura

```mermaid
graph TB
    %% Styling
    classDef awsService fill:#ff9900,stroke:#ff6600,stroke-width:2px,color:#fff
    classDef k8sService fill:#326ce5,stroke:#1a73e8,stroke-width:2px,color:#fff
    classDef appService fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff
    classDef monitoring fill:#632ca6,stroke:#7c4dff,stroke-width:2px,color:#fff
    classDef cicd fill:#24292e,stroke:#586069,stroke-width:2px,color:#fff
    classDef network fill:#146eb4,stroke:#0d47a1,stroke-width:2px,color:#fff
    
    %% External Services
    subgraph "ğŸŒ External Services"
        GH[ğŸ™ GitHub Actions<br/>CI/CD + OIDC]:::cicd
        DD[ğŸ• Datadog SaaS<br/>APM + Metrics + Logs]:::monitoring
        USER[ğŸ‘¥ End Users<br/>Web + Mobile]:::appService
    end
    
    %% AWS Cloud
    subgraph "â˜ï¸ AWS Cloud (us-east-1)"
        subgraph "ğŸŒ VPC (10.0.0.0/16)"
            
            subgraph "ğŸ¢ Availability Zone A"
                subgraph "ğŸŒ Public Subnet A (10.0.101.0/24)"
                    IGW[ğŸŒ Internet Gateway]:::network
                    NAT[ğŸ”€ NAT Gateway]:::network
                end
                
                subgraph "ğŸ”’ Private Subnet A (10.0.1.0/24)"
                    PODS_A[ğŸš€ EKS Fargate Pods A]:::k8sService
                end
            end
            
            subgraph "ğŸ¢ Availability Zone B"
                subgraph "ğŸŒ Public Subnet B (10.0.102.0/24)"
                    ALB[âš–ï¸ Application Load Balancer<br/>Ingress Controller]:::network
                end
                
                subgraph "ğŸ”’ Private Subnet B (10.0.2.0/24)"
                    PODS_B[ğŸš€ EKS Fargate Pods B]:::k8sService
                end
            end
            
            subgraph "ğŸ›ï¸ EKS Control Plane (Multi-AZ)"
                API[âš™ï¸ Kubernetes API Server]:::k8sService
                COREDNS[ğŸ” CoreDNS<br/>(Fargate Profile)]:::k8sService
                ETCD[ğŸ’¾ Managed Etcd]:::k8sService
            end
        end
        
        subgraph "ğŸ”§ AWS Managed Services"
            DDB[ğŸ—ƒï¸ DynamoDB<br/>orders table<br/>Pay-per-request]:::awsService
            ECR[ğŸ“¦ Elastic Container Registry<br/>backend + frontend images]:::awsService
            SM[ğŸ” Secrets Manager<br/>API Keys + Credentials]:::awsService
            CW[ğŸ“Š CloudWatch<br/>Logs + Metrics]:::awsService
            IAM[ğŸ­ IAM + OIDC<br/>IRSA Roles]:::awsService
        end
    end
    
    %% Application Layer Detail
    subgraph "ğŸ“± Application Services (EKS Namespace: case)"
        subgraph "ğŸ”µ Blue/Green Deployments"
            BACKEND_BLUE[ğŸš€ Backend Service (Blue)<br/>Node.js + Express<br/>dd-trace APM]:::appService
            BACKEND_GREEN[ğŸš€ Backend Service (Green)<br/>Node.js + Express<br/>dd-trace APM]:::appService
            
            FRONTEND_BLUE[ğŸ¨ Frontend Service (Blue)<br/>React + Vite + Nginx]:::appService
            FRONTEND_GREEN[ğŸ¨ Frontend Service (Green)<br/>React + Vite + Nginx]:::appService
            
            MOBILE[ğŸ“± Mobile Service<br/>Expo Web (Optional)]:::appService
        end
        
        subgraph "âš–ï¸ Load Balancing"
            SVC_BACKEND[ğŸ”„ Backend Service<br/>ClusterIP + Selector]:::k8sService
            SVC_FRONTEND[ğŸ”„ Frontend Service<br/>ClusterIP + Selector]:::k8sService
            SVC_MOBILE[ğŸ”„ Mobile Service<br/>ClusterIP]:::k8sService
        end
        
        subgraph "ğŸ¯ Ingress Routing"
            INGRESS[ğŸŒ Nginx Ingress<br/>Path-based routing<br/>SSL/TLS termination]:::k8sService
        end
    end
    
    %% Dataflow Connections
    USER -->|HTTPS Traffic| ALB
    ALB -->|Route Traffic| INGRESS
    INGRESS -->|/api/*| SVC_BACKEND
    INGRESS -->|/*| SVC_FRONTEND
    INGRESS -->|/mobile/*| SVC_MOBILE
    
    SVC_BACKEND -.->|Blue/Green Switch| BACKEND_BLUE
    SVC_BACKEND -->|Active| BACKEND_GREEN
    SVC_FRONTEND -.->|Blue/Green Switch| FRONTEND_BLUE
    SVC_FRONTEND -->|Active| FRONTEND_GREEN
    SVC_MOBILE --> MOBILE
    
    %% Backend integrations
    BACKEND_GREEN -->|IRSA Auth| DDB
    BACKEND_BLUE -->|IRSA Auth| DDB
    
    %% CI/CD Flow
    GH -->|Build & Push| ECR
    GH -->|Deploy via kubectl| API
    GH -->|OIDC Assume Role| IAM
    
    %% Monitoring & Observability
    BACKEND_GREEN -->|APM Agentless| DD
    BACKEND_BLUE -->|APM Agentless| DD
    FRONTEND_GREEN -->|Browser RUM| DD
    PODS_A -->|Cluster Metrics| DD
    PODS_B -->|Cluster Metrics| DD
    CW -->|Log Forwarding| DD
    
    %% Infrastructure connections
    PODS_A --> API
    PODS_B --> API
    API --> ETCD
    API --> COREDNS
    
    %% Secrets and Config
    SM -->|API Keys| BACKEND_GREEN
    SM -->|API Keys| BACKEND_BLUE
    IAM -->|ServiceAccount Auth| BACKEND_GREEN
    IAM -->|ServiceAccount Auth| BACKEND_BLUE
    
    %% Networking
    IGW -->|Internet Access| NAT
    NAT -->|Egress Traffic| PODS_A
    NAT -->|Egress Traffic| PODS_B
```

## Fluxo de Deploy Blue/Green

```mermaid
sequenceDiagram
    participant GH as GitHub Actions
    participant ECR as Amazon ECR
    participant K8S as EKS Cluster
    participant ALB as Load Balancer
    participant BLUE as Blue Deployment
    participant GREEN as Green Deployment
    participant SVC as Service
    participant DD as Datadog
    
    Note over GH,DD: Blue/Green Deployment Process
    
    GH->>ECR: 1. Build & Push new image
    GH->>K8S: 2. Create Green deployment
    K8S->>GREEN: 3. Deploy new version (Green)
    
    loop Health Check
        GH->>GREEN: 4. Validate pods healthy
        GREEN-->>GH: Ready
    end
    
    GH->>K8S: 5. Run smoke tests
    K8S-->>GH: Tests passed
    
    GH->>SVC: 6. Switch service selector: blueâ†’green
    ALB->>GREEN: 7. Route traffic to Green
    
    Note over BLUE,GREEN: Traffic switched
    
    GREEN->>DD: 8. New APM traces
    DD-->>GH: 9. Metrics validation
    
    opt Rollback if needed
        GH->>SVC: Switch back: greenâ†’blue
        ALB->>BLUE: Route traffic to Blue
    end
    
    GH->>K8S: 10. Cleanup old Blue deployment
```

## Observabilidade e Monitoramento

### OpÃ§Ã£o 1: Datadog SaaS (Principal)

```mermaid
graph LR
    %% Application Sources
    subgraph "ğŸ“± Application Layer"
        APP[ğŸš€ Backend Service<br/>dd-trace APM]
        WEB[ğŸ¨ Frontend<br/>Browser RUM]
        MOBILE[ğŸ“± Mobile App]
    end
    
    %% Infrastructure Sources  
    subgraph "ğŸ—ï¸ Infrastructure Layer"
        EKS[âš™ï¸ EKS Cluster<br/>Cluster Agent]
        AWS[â˜ï¸ AWS Services<br/>CloudWatch]
        NET[ğŸŒ Network<br/>VPC Flow Logs]
    end
    
    %% Datadog Platform
    subgraph "ğŸ• Datadog Platform"
        APM[ğŸ” APM<br/>Traces + Profiling]
        METRICS[ğŸ“Š Infrastructure<br/>Metrics + Custom]
        LOGS[ğŸ“ Log Management<br/>Parsing + Analytics]
        ALERTS[ğŸš¨ Alerting<br/>Monitors + SLOs]
        DASH[ğŸ“ˆ Dashboards<br/>Golden Signals + Business]
    end
    
    %% Connections
    APP -->|Agentless Traces| APM
    WEB -->|Real User Monitoring| APM
    MOBILE -->|Mobile RUM| APM
    
    EKS -->|Cluster Metrics| METRICS
    AWS -->|CloudWatch Integration| METRICS
    AWS -->|Log Forwarding| LOGS
    NET -->|Network Metrics| METRICS
    
    APM --> ALERTS
    METRICS --> ALERTS
    LOGS --> ALERTS
    
    APM --> DASH
    METRICS --> DASH
    LOGS --> DASH
    
    %% Styling
    classDef appLayer fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff
    classDef infraLayer fill:#ff9900,stroke:#ff6600,stroke-width:2px,color:#fff
    classDef ddPlatform fill:#632ca6,stroke:#7c4dff,stroke-width:2px,color:#fff
    
    class APP,WEB,MOBILE appLayer
    class EKS,AWS,NET infraLayer
    class APM,METRICS,LOGS,ALERTS,DASH ddPlatform
```

### OpÃ§Ã£o 2: Grafana Stack (Alternativa/HÃ­brida)

```mermaid
graph TB
    %% Application Sources
    subgraph "ğŸ“± Application Services"
        BACKEND[ğŸš€ Backend<br/>Node.js + Express]
        FRONTEND[ğŸ¨ Frontend<br/>React + Vite]
        MOBILE[ğŸ“± Mobile<br/>Expo Web]
    end
    
    %% Data Sources
    subgraph "ğŸ“Š Data Collection"
        METRICS_EP[ğŸ“ˆ /metrics endpoint<br/>Prometheus format]
        LOGS_JSON[ğŸ“ JSON Logs<br/>Pino structured]
        TRACES_OTLP[ğŸ” OpenTelemetry<br/>OTLP/gRPC]
    end
    
    %% Grafana Stack Components
    subgraph "ğŸ”¶ Grafana Observability Stack"
        subgraph "ğŸ“Š Metrics"
            PROM[ğŸ“Š Prometheus<br/>Time Series DB<br/>Scraping + Storage]
            ALERT_MGR[ğŸš¨ AlertManager<br/>Notifications<br/>Slack + PagerDuty]
        end
        
        subgraph "ğŸ“ Logs"
            PROMTAIL[ğŸ“¤ Promtail<br/>Log Shipper<br/>Docker + K8s labels]
            LOKI[ğŸ“š Loki<br/>Log Aggregation<br/>LogQL queries]
        end
        
        subgraph "ğŸ” Traces"
            TEMPO[âš¡ Tempo<br/>Distributed Tracing<br/>TraceQL + S3 storage]
        end
        
        subgraph "ğŸ“ˆ Visualization"
            GRAFANA[ğŸ“Š Grafana<br/>Unified Dashboards<br/>Multi-datasource]
        end
    end
    
    %% External Storage
    subgraph "â˜ï¸ AWS Storage"
        S3_METRICS[ğŸ—‚ï¸ S3: Prometheus<br/>Long-term metrics]
        S3_LOGS[ğŸ—‚ï¸ S3: Loki chunks<br/>30 days retention]
        S3_TRACES[ğŸ—‚ï¸ S3: Tempo blocks<br/>Compressed traces]
    end
    
    %% Data Flow
    BACKEND --> METRICS_EP
    BACKEND --> LOGS_JSON
    BACKEND --> TRACES_OTLP
    
    FRONTEND --> LOGS_JSON
    MOBILE --> LOGS_JSON
    
    %% Collection
    METRICS_EP -->|HTTP scrape| PROM
    LOGS_JSON -->|Docker socket| PROMTAIL
    TRACES_OTLP -->|OTLP/gRPC| TEMPO
    
    %% Processing
    PROMTAIL -->|Push API| LOKI
    PROM -->|Alert rules| ALERT_MGR
    
    %% Storage
    PROM -->|Remote write| S3_METRICS
    LOKI -->|Chunks| S3_LOGS
    TEMPO -->|Blocks| S3_TRACES
    
    %% Visualization
    PROM -->|PromQL| GRAFANA
    LOKI -->|LogQL| GRAFANA
    TEMPO -->|TraceQL| GRAFANA
    
    %% Alerting
    ALERT_MGR -->|Webhooks| SLACK[ğŸ“¢ Slack]
    ALERT_MGR -->|API| PAGER[ğŸ“Ÿ PagerDuty]
    
    %% Styling
    classDef apps fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff
    classDef data fill:#2196f3,stroke:#1976d2,stroke-width:2px,color:#fff
    classDef grafana fill:#ff6d00,stroke:#d84315,stroke-width:2px,color:#fff
    classDef storage fill:#607d8b,stroke:#455a64,stroke-width:2px,color:#fff
    classDef external fill:#9c27b0,stroke:#7b1fa2,stroke-width:2px,color:#fff
    
    class BACKEND,FRONTEND,MOBILE apps
    class METRICS_EP,LOGS_JSON,TRACES_OTLP data
    class PROM,LOKI,TEMPO,GRAFANA,PROMTAIL,ALERT_MGR grafana
    class S3_METRICS,S3_LOGS,S3_TRACES storage
    class SLACK,PAGER external
```

### EstratÃ©gia HÃ­brida: Datadog + Grafana

```mermaid
graph TB
    %% Applications
    subgraph "ğŸš€ Production Applications"
        APPS[Backend + Frontend + Mobile<br/>Multi-instrument approach]
    end
    
    %% Primary Stack: Datadog
    subgraph "ğŸ• Primary: Datadog SaaS"
        DD_APM[APM Agentless<br/>Critical alerting<br/>24/7 SLA]
        DD_DASH[Executive Dashboards<br/>Business metrics<br/>Auto-correlation]
        DD_ALERT[Smart Alerting<br/>ML-based anomalies<br/>PagerDuty integration]
    end
    
    %% Secondary Stack: Grafana
    subgraph "ğŸ”¶ Secondary: Grafana Stack"
        G_METRICS[Cost Analysis<br/>Custom metrics<br/>Long-term storage]
        G_LOGS[Compliance logs<br/>Audit trails<br/>Historical analysis]
        G_TRACES[Custom sampling<br/>Debug workflows<br/>Performance tuning]
    end
    
    %% Use Cases
    subgraph "ğŸ¯ Use Cases"
        UC1[ğŸš¨ Critical Incidents<br/>Use Datadog for MTTR]
        UC2[ğŸ’° Cost Optimization<br/>Use Grafana for FinOps]
        UC3[ğŸ“Š Executive Reports<br/>Use Datadog dashboards]
        UC4[ğŸ” Deep Debugging<br/>Use Grafana Explore]
        UC5[ğŸ“‹ Compliance<br/>Use Grafana logs]
    end
    
    %% Data Flow
    APPS -->|Primary telemetry| DD_APM
    APPS -->|Secondary telemetry| G_METRICS
    
    DD_APM --> DD_DASH
    DD_APM --> DD_ALERT
    
    G_METRICS --> G_LOGS
    G_METRICS --> G_TRACES
    
    %% Use Case Connections
    DD_ALERT --> UC1
    G_METRICS --> UC2
    DD_DASH --> UC3
    G_TRACES --> UC4
    G_LOGS --> UC5
    
    %% Styling
    classDef apps fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff
    classDef datadog fill:#632ca6,stroke:#7c4dff,stroke-width:2px,color:#fff
    classDef grafana fill:#ff6d00,stroke:#d84315,stroke-width:2px,color:#fff
    classDef usecases fill:#607d8b,stroke:#455a64,stroke-width:2px,color:#fff
    
    class APPS apps
    class DD_APM,DD_DASH,DD_ALERT datadog
    class G_METRICS,G_LOGS,G_TRACES grafana
    class UC1,UC2,UC3,UC4,UC5 usecases
```

## SeguranÃ§a e Compliance

```mermaid
graph TD
    %% External Identity
    subgraph "ğŸ” External Identity"
        GH_OIDC[ğŸ™ GitHub OIDC<br/>Temporary credentials]
        DD_API[ğŸ• Datadog API<br/>Encrypted keys]
    end
    
    %% AWS Security Services
    subgraph "ğŸ›¡ï¸ AWS Security Layer"
        IAM_OIDC[ğŸ­ IAM OIDC Provider<br/>Trust relationship]
        IRSA[ğŸ”‘ IRSA Roles<br/>Service Account mapping]
        SM[ğŸ” Secrets Manager<br/>Encrypted secrets]
        KMS[ğŸ”’ AWS KMS<br/>Encryption keys]
    end
    
    %% Network Security
    subgraph "ğŸŒ Network Security"
        VPC[ğŸ  VPC<br/>Isolated network]
        SG[ğŸ›¡ï¸ Security Groups<br/>Firewall rules]
        NACL[ğŸš§ Network ACLs<br/>Subnet protection]
        PRIV[ğŸ”’ Private Subnets<br/>No public IPs]
    end
    
    %% Kubernetes Security
    subgraph "âš™ï¸ K8s Security"
        SA[ğŸ‘¤ Service Accounts<br/>Pod identity]
        RBAC[ğŸ¯ RBAC<br/>Permission control]
        NET_POL[ğŸ•¸ï¸ Network Policies<br/>Pod-to-pod rules]
        PSS[ğŸ›¡ï¸ Pod Security Standards<br/>Security context]
    end
    
    %% Container Security
    subgraph "ğŸ“¦ Container Security"
        ECR_SCAN[ğŸ” ECR Image Scanning<br/>Vulnerability detection]
        NONROOT[ğŸ‘¤ Non-root user<br/>Container hardening]
        RO_FS[ğŸ“ Read-only filesystem<br/>Immutable containers]
        SECRETS[ğŸ” Secret mounting<br/>Runtime secrets]
    end
    
    %% Connections
    GH_OIDC --> IAM_OIDC
    IAM_OIDC --> IRSA
    IRSA --> SA
    SA --> RBAC
    
    SM --> KMS
    SM --> SECRETS
    DD_API --> SM
    
    VPC --> SG
    VPC --> NACL
    VPC --> PRIV
    PRIV --> NET_POL
    
    ECR_SCAN --> NONROOT
    NONROOT --> RO_FS
    RO_FS --> PSS
    
    %% Styling
    classDef external fill:#24292e,stroke:#586069,stroke-width:2px,color:#fff
    classDef awsSec fill:#ff9900,stroke:#ff6600,stroke-width:2px,color:#fff
    classDef network fill:#146eb4,stroke:#0d47a1,stroke-width:2px,color:#fff
    classDef k8sSec fill:#326ce5,stroke:#1a73e8,stroke-width:2px,color:#fff
    classDef container fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff
    
    class GH_OIDC,DD_API external
    class IAM_OIDC,IRSA,SM,KMS awsSec
    class VPC,SG,NACL,PRIV network
    class SA,RBAC,NET_POL,PSS k8sSec
    class ECR_SCAN,NONROOT,RO_FS,SECRETS container
```

## Custos e FinOps

### Infraestrutura Base AWS

| Componente | Custo Mensal (USD) | Tipo de CobranÃ§a | OtimizaÃ§Ã£o |
|------------|-------------------|------------------|------------|
| **EKS Control Plane** | ~$73 | Fixo 24/7 | Compartilhar entre ambientes |
| **Fargate Pods** | ~$50-150 | vCPU + RAM por segundo | Right-sizing + HPA |
| **DynamoDB** | ~$5-25 | Pay-per-request | Avaliar reserved capacity |
| **NAT Gateway** | ~$45 | Fixo + dados processados | VPC Endpoints para reduzir egress |
| **CloudWatch Logs** | ~$5-15 | Volume + retenÃ§Ã£o | Filtros + retenÃ§Ã£o otimizada |
| **ECR** | ~$1-5 | Storage usado | Lifecycle policies |
| **Application Load Balancer** | ~$22 | Fixo + LCU | Consolidar ingress |
| **Subtotal Infra** | **~$201-335** | | |

### ComparaÃ§Ã£o de Observabilidade: Datadog vs Grafana Stack

| Aspecto | Datadog SaaS | Grafana Stack | Economia |
|---------|--------------|---------------|-----------|
| **Setup Cost** | $0 (SaaS) | $2000-5000 (engineering time) | - |
| **Monthly Cost** | | | |
| â€¢ APM (5 hosts) | $155 | $30 (Fargate pods) | 80% |
| â€¢ Log Ingestion (100GB) | $110 | $5 (S3 storage) | 95% |
| â€¢ Metrics (custom) | $60 | $15 (Prometheus storage) | 75% |
| â€¢ Dashboards/Alerts | IncluÃ­do | $15 (Grafana pod) | - |
| â€¢ **Subtotal Observabilidade** | **$325** | **$65** | **80%** |
| **Operational Cost** | $0 | $3000-5000/mÃªs (1 SRE) | - |
| **Training Cost** | Baixo | Alto (Prometheus/Grafana) | - |
| **Vendor Lock-in Risk** | Alto | Baixo | - |

### AnÃ¡lise TCO (Total Cost of Ownership) - 12 meses

| CenÃ¡rio | Datadog | Grafana Stack | DiferenÃ§a |
|---------|---------|---------------|-----------|
| **Custos Diretos** | | | |
| â€¢ Software/SaaS | $3,900 | $780 | -$3,120 |
| â€¢ Infrastructure | IncluÃ­do | $780 | +$780 |
| **Custos Indiretos** | | | |
| â€¢ Setup inicial | $0 | $5,000 | +$5,000 |
| â€¢ Operational (12m) | $0 | $42,000 | +$42,000 |
| â€¢ Training | $2,000 | $8,000 | +$6,000 |
| **Total 12 meses** | **$5,900** | **$56,560** | **+$50,660** |

### EstratÃ©gia HÃ­brida - Custo Otimizado

| Ambiente | Stack Principal | Stack SecundÃ¡ria | Custo/mÃªs |
|----------|----------------|------------------|-----------|
| **Production** | Datadog (critical) | Grafana (analytics) | $250 + $30 = $280 |
| **Staging** | Grafana | - | $65 |
| **Development** | Grafana | - | $65 |
| **Total** | | | **$410/mÃªs** |

**BenefÃ­cios da EstratÃ©gia HÃ­brida:**
- ğŸ“‰ **37% economia** vs Datadog puro
- ğŸš¨ **Zero compromisso** em alertas crÃ­ticos  
- ğŸ“Š **Flexibilidade** para anÃ¡lises customizadas
- ğŸ“ **Learning path** para eventual migraÃ§Ã£o
- ğŸ“‹ **Compliance** com logs de longo prazo

### EstratÃ©gias de OtimizaÃ§Ã£o:

1. **Compute (Fargate)**:
   - Resource requests/limits precisos
   - HPA com mÃ©tricas customizadas
   - Spot instances quando disponÃ­vel

2. **Storage**:
   - ECR lifecycle policies
   - CloudWatch logs retention
   - DynamoDB TTL para dados temporÃ¡rios

3. **Network**:
   - VPC Endpoints para reduzir NAT costs
   - CloudFront para assets estÃ¡ticos
   - Datadog intake via PrivateLink

4. **Monitoring**:
   - Tags para cost allocation
   - AWS Cost Explorer + Budgets
   - Datadog usage tracking

## SLAs e MÃ©tricas de Performance

| MÃ©trica | Target | MediÃ§Ã£o | Alertas |
|---------|--------|---------|---------|
| **Availability** | 99.9% | Uptime monitoring | < 99.5% |
| **Latency P95** | < 200ms | APM traces | > 500ms |
| **Error Rate** | < 1% | HTTP 5xx responses | > 5% |
| **Throughput** | Baseline + 50% | Requests/second | Capacity alerts |
| **MTTR** | < 15min | Incident response | SLA breach |

### Golden Signals Dashboard:
- **Latency**: P50, P95, P99 response times
- **Traffic**: Request rate, active users
- **Errors**: Error rate por endpoint, status codes
- **Saturation**: CPU, memoria, DynamoDB throttling